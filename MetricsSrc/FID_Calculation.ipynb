{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vgg19, VGG19_Weights\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "File \u001b[0;32m~/anaconda3/envs/cnet_gud/lib/python3.12/site-packages/torchvision/__init__.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cnet_gud/lib/python3.12/site-packages/torchvision/datasets/__init__.py:32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgtsrb\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GTSRB\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhmdb51\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HMDB51\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimagenet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageNet\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimagenette\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Imagenette\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minaturalist\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m INaturalist\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1091\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1191\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Base directory containing the ten cities\n",
    "base_dir = \"./urban_data/tencities/GenAI_density\"\n",
    "\n",
    "# List of cities\n",
    "cities = [\n",
    "    'Singapore',\n",
    "    'HongKong',\n",
    "    'Munich',\n",
    "    'Stockholm',\n",
    "    'Chicago',\n",
    "    'Orlando',\n",
    "    'Kinshasa',\n",
    "    'SaoPaulo',\n",
    "    'Mexico',\n",
    "    'Kigali'\n",
    "]\n",
    "\n",
    "# Define which file extensions to consider as images\n",
    "image_extensions = (\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\")\n",
    "\n",
    "# How many images to sample per city\n",
    "sample_size = 1000\n",
    "\n",
    "for city in cities:\n",
    "    # Specifically look in {city}/satellite_images_z17\n",
    "    city_satellite_dir = os.path.join(base_dir, city, \"satellite_images_z17\")\n",
    "    if not os.path.isdir(city_satellite_dir):\n",
    "        print(f\"Warning: directory does not exist for {city}: {city_satellite_dir}\")\n",
    "        continue\n",
    "\n",
    "    # Collect all image filepaths recursively from satellite_images_z17\n",
    "    city_img_files = []\n",
    "    for root, dirs, files in os.walk(city_satellite_dir):\n",
    "        for filename in files:\n",
    "            if filename.lower().endswith(image_extensions):\n",
    "                full_path = os.path.join(root, filename)\n",
    "                city_img_files.append(full_path)\n",
    "\n",
    "    # Randomly shuffle and take up to 1000\n",
    "    random.shuffle(city_img_files)\n",
    "    selected_files = city_img_files[:sample_size]\n",
    "\n",
    "    # Write these image paths to a JSON file within the city folder\n",
    "    out_json = os.path.join(base_dir, city, f\"{city}_img_paths_sf.json\")\n",
    "    with open(out_json, 'w') as outfile:\n",
    "        json.dump(selected_files, outfile, indent=2)\n",
    "\n",
    "    print(f\"Saved {len(selected_files)} image paths for {city} -> {out_json}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 299 matching filenames.\n",
      "Groupings extracted and saved to: /Users/wangzhuoyulucas/SMART /data_server/urban_data/tencities/GenAI_density/groupings_newFID.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import re\n",
    "# YOUR OWN GENERATED IMAGE DIRECTORY\n",
    "showcase_dir = \"/Users/wangzhuoyulucas/SMART /generatedImg/show-case-FID\"\n",
    "\n",
    "groupings_output = \"/Users/wangzhuoyulucas/SMART /data_server/urban_data/tencities/GenAI_density/groupings_newFID.json\"\n",
    "\n",
    "# 1) Define multiple regex patterns\n",
    "patterns = [\n",
    "    # a) original pattern: something containing \"_cv.jpg\" and ending \"_gt.png\"\n",
    "    re.compile(r'_cv\\.jpg.*_gt\\.png$', re.IGNORECASE),\n",
    "    \n",
    "    # b) pattern for e.g. \"34_45_r0_d0_cv.jpggt-Chicago\"\n",
    "    #    or \"61_52_r0_d1_cv.jpggt-Mexico.png\"\n",
    "    #    We look for \"_cv.jpggt-\" + (some city text) + optional extension\n",
    "    #    NOTE: Adjust character class [^.]+ if city names can have spaces, etc.\n",
    "    re.compile(r'_cv\\.jpggt-[^.]+(\\.png|\\.jpg|\\.jpeg|\\.tiff|\\.bmp)?$', re.IGNORECASE),\n",
    "]\n",
    "\n",
    "groupings_list = []\n",
    "\n",
    "for fname in os.listdir(showcase_dir):\n",
    "    # Skip directories\n",
    "    if os.path.isdir(os.path.join(showcase_dir, fname)):\n",
    "        continue\n",
    "    \n",
    "    # Check each pattern; if any matches, we collect it\n",
    "    for pat in patterns:\n",
    "        if pat.search(fname):\n",
    "            groupings_list.append(fname)\n",
    "            break  # stop checking other patterns once matched\n",
    "\n",
    "# Save to JSON\n",
    "with open(groupings_output, 'w') as f:\n",
    "    json.dump(groupings_list, f, indent=2)\n",
    "\n",
    "print(f\"Found {len(groupings_list)} matching filenames.\")\n",
    "print(f\"Groupings extracted and saved to: {groupings_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move files into new sampled folder (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# 1) List of city names and JSON filenames\n",
    "cities = [\n",
    "    \"Singapore\",\n",
    "    \"HongKong\",\n",
    "    \"Munich\",\n",
    "    \"Stockholm\",\n",
    "    \"Chicago\",\n",
    "    \"Orlando\",\n",
    "    \"Kinshasa\",\n",
    "    \"SaoPaulo\",\n",
    "    \"Mexico\",\n",
    "    \"Kigali\"\n",
    "]\n",
    "\n",
    "# 2) Base path where the JSON files live, e.g.:\n",
    "json_dir = \"./urban_data/tencities/GenAI_density\"\n",
    "\n",
    "# 3) Output base directory for the final copied images\n",
    "#    (adjust as needed)\n",
    "destination_root = \"./urban_data/tencities/GenAI_density/cities_sampled1\"\n",
    "\n",
    "# Ensure the final root directory exists\n",
    "if not os.path.exists(destination_root):\n",
    "    os.makedirs(destination_root)\n",
    "\n",
    "# 4) Loop over the cities\n",
    "for city in cities:\n",
    "    # Construct the JSON path for each city\n",
    "    json_filename = f\"{city}/{city}_img_paths_sf.json\"  \n",
    "    json_path = os.path.join(json_dir, json_filename)\n",
    "\n",
    "    if not os.path.isfile(json_path):\n",
    "        print(f\"[WARN] JSON file not found for {city}: {json_path}\")\n",
    "        continue\n",
    "\n",
    "    # 5) Load the list of image paths\n",
    "    with open(json_path, \"r\") as f:\n",
    "        image_paths = json.load(f)  # a list of file paths (strings)\n",
    "\n",
    "    # 6) Create the city-specific output folder\n",
    "    city_output_folder = os.path.join(destination_root, city)\n",
    "    os.makedirs(city_output_folder, exist_ok=True)\n",
    "\n",
    "    # 7) Copy each image from its source to the city output folder\n",
    "    print(f\"[INFO] Copying {len(image_paths)} images for {city} into {city_output_folder} ...\")\n",
    "    for src_path in image_paths:\n",
    "        if not os.path.isfile(src_path):\n",
    "            print(f\"  [WARN] Source image not found: {src_path}\")\n",
    "            continue\n",
    "\n",
    "        # Construct a destination filename\n",
    "        # If two files have the same basename, you might overwrite. \n",
    "        # Consider adding logic to handle duplicates (renaming, etc.).\n",
    "        filename = os.path.basename(src_path)\n",
    "        dst_path = os.path.join(city_output_folder, filename)\n",
    "\n",
    "        # Copy file (including metadata)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "\n",
    "    print(f\"[INFO] Done copying for {city}\")\n",
    "\n",
    "print(\"[INFO] All copying complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pytorch-fid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FID Calculation GPU (pls change your directory accordingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import torch  # Import torch to check GPU\n",
    "from tqdm import tqdm\n",
    "\n",
    "# **1) Define Paths**\n",
    "base_real_dir = \"./urban_data/tencities/GenAI_density/cities_sampled1\"\n",
    "base_generated_dir = \"./urban_data/tencities/GenAI_density/cities_sampled/city_generated\"\n",
    "\n",
    "# **2) List of Cities**\n",
    "cities = [\n",
    "    \"Singapore\", \"HongKong\", \"Munich\", \"Stockholm\", \"Chicago\",\n",
    "    \"Orlando\", \"Kinshasa\", \"SaoPaulo\", \"Mexico\", \"Kigali\"\n",
    "]\n",
    "\n",
    "# **3) Verify GPU is Available**\n",
    "device = \"cuda:9\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"[INFO] Running on device: {device}\")\n",
    "\n",
    "# **4) Initialize Results Storage**\n",
    "results = []\n",
    "\n",
    "# **5) Loop through City Pairs & Compute FID**\n",
    "for city in tqdm(cities, desc=\"Computing FID for city pairs\"):\n",
    "    real_folder = os.path.join(base_real_dir, city)\n",
    "    generated_folder = os.path.join(base_generated_dir, f\"{city}_generated\")\n",
    "\n",
    "    # **Check if folders exist**\n",
    "    if not os.path.isdir(real_folder):\n",
    "        print(f\"[WARN] Real image folder missing: {real_folder}\")\n",
    "        continue\n",
    "    if not os.path.isdir(generated_folder):\n",
    "        print(f\"[WARN] Generated image folder missing: {generated_folder}\")\n",
    "        continue\n",
    "\n",
    "    # **Run pytorch_fid command**\n",
    "    print(f\"[INFO] Computing FID for {city} on device {device}...\")\n",
    "    try:\n",
    "        cmd = [\n",
    "            \"python\", \"-m\", \"pytorch_fid\",\n",
    "            generated_folder, real_folder,\n",
    "            \"--device\", device\n",
    "        ]\n",
    "        output = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        \n",
    "        # Print raw output to check if GPU is detected\n",
    "        print(output.stdout)\n",
    "\n",
    "        # Extract FID score (last number from stdout)\n",
    "        fid_score = None\n",
    "        for line in output.stdout.split(\"\\n\"):\n",
    "            if \"FID:\" in line:\n",
    "                fid_score = float(line.split()[-1])  # Last value in the line\n",
    "\n",
    "        results.append({\"City\": city, \"FID\": fid_score})\n",
    "        print(f\"[INFO] {city} -> FID: {fid_score}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to compute FID for {city}: {e}\")\n",
    "        results.append({\"City\": city, \"FID\": None})\n",
    "\n",
    "# **6) Save FID Results to CSV**\n",
    "df = pd.DataFrame(results)\n",
    "output_csv = \"./urban_data/tencities/GenAI_density/fid_results.csv\"\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"[INFO] FID scores saved to: {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnet_gud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
